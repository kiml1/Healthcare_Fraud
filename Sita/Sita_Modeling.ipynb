{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.linear_model import \\\n",
    "    LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.ensemble import \\\n",
    "    RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "providers = load('./data/Providers_Final.pkl')\n",
    "providers.set_index('Provider', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = providers.drop('PotentialFraud', axis=1)\n",
    "y = providers.PotentialFraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ms.train_test_split(\n",
    "    X, y, test_size = 0.3, random_state = 0, stratify=y)\n",
    "\n",
    "# # 70/30 split gives roughly the same baseline model results\n",
    "# # but saves grid_search time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scale only the training data to avoid data leakage\n",
    "scaler = pp.MinMaxScaler()\n",
    "\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stratify folds so that classes always have the same sample ratio\n",
    "skfold = ms.StratifiedKFold(n_splits=10, random_state=0, shuffle=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # baseline model\n",
    "\n",
    "# # L1 penalty for feature selection, liblinear solver faster than saga\n",
    "# logRegCV = \\\n",
    "#     LogisticRegressionCV(penalty='l1', solver='liblinear', cv=skfold,\n",
    "#                          class_weight='balanced', scoring='recall',\n",
    "#                          random_state=0, n_jobs=(-1), verbose=1)\n",
    "\n",
    "# logRegCV.fit(X_train, y_train)\n",
    "\n",
    "# # dump(logRegCV, './data/logRegCV.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # grid search with accuracy scoring metric\n",
    "\n",
    "# logRegGSAccuracy = ms.GridSearchCV(logRegModel, param_grid=params,\n",
    "#                                    cv=skfold, n_jobs=(-1), verbose=1)\n",
    "\n",
    "# logRegAccuracy = logRegGSAccuracy.fit(X_train, y_train)\n",
    "# bestLogRegAccuracy = logRegAccuracy.best_estimator_\n",
    "\n",
    "# # dump(bestLogRegAccuracy, './data/bestLogRegAccuracy.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # grid search with recall scoring metric\n",
    "\n",
    "# # can't use scoring param, need to use recall_score()\n",
    "# logRegModel = \\\n",
    "#     LogisticRegression(penalty='l1', solver='liblinear',\n",
    "#                        class_weight='balanced', random_state=0,\n",
    "#                        n_jobs=(-1), verbose=1)\n",
    "\n",
    "# params = {'C': np.logspace(-2, 2, 50),\n",
    "#           'max_iter': [100, 500, 1000]}\n",
    "\n",
    "# logRegGS = ms.GridSearchCV(logRegModel, param_grid=params,\n",
    "#                            scoring='recall', cv=skfold, verbose=1)\n",
    "\n",
    "# logReg = logRegGS.fit(X_train, y_train)\n",
    "# bestLogReg = logReg.best_estimator_\n",
    "\n",
    "# # dump(bestLogReg, './data/bestLogReg.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9180790960451978\n",
      "0.9144736842105263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sitat\\anaconda3\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator LogisticRegressionCV from version 0.22.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# # baseline model\n",
    "logRegCV = load('./data/logRegCV.pkl')\n",
    "\n",
    "print(recall_score(y_train, logRegCV.predict(X_train)))\n",
    "print(recall_score(y_test, logRegCV.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9152542372881356\n",
      "0.8289473684210527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sitat\\anaconda3\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# # grid search with accuracy scoring metric\n",
    "bestLogRegAccuracy = load('./data/bestLogRegAccuracy.pkl')\n",
    "\n",
    "# print(bestLogRegAccuracy)\n",
    "print(recall_score(y_train, bestLogRegAccuracy.predict(X_train)))\n",
    "print(recall_score(y_test, bestLogRegAccuracy.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9265536723163842\n",
      "0.9210526315789473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sitat\\anaconda3\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# # grid search with recall scoring metric\n",
    "bestLogReg = load('./data/bestLogReg.pkl')\n",
    "\n",
    "# print(bestLogReg)\n",
    "print(recall_score(y_train, bestLogReg.predict(X_train)))\n",
    "print(recall_score(y_test, bestLogReg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PatientsPerOthPhys</th>\n",
       "      <td>7.691565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ratio_ClaimsPerPatient</th>\n",
       "      <td>3.215364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IP_Count_UniquePatients</th>\n",
       "      <td>3.138851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perc_Outpatient</th>\n",
       "      <td>1.847467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DualPatientProvider</th>\n",
       "      <td>1.636980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP_Perc_MultHosp</th>\n",
       "      <td>0.674412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IP_Mean_InsReimbursementRatio</th>\n",
       "      <td>0.379315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP_Count_UniqueState</th>\n",
       "      <td>0.228130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IP_Perc_HeartFailure_Chronic</th>\n",
       "      <td>0.143150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perc_MultHospAttPhys</th>\n",
       "      <td>0.057042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IP_Perc_Depression_Chronic</th>\n",
       "      <td>0.005872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Coefficient\n",
       "PatientsPerOthPhys                7.691565\n",
       "Ratio_ClaimsPerPatient            3.215364\n",
       "IP_Count_UniquePatients           3.138851\n",
       "Perc_Outpatient                   1.847467\n",
       "DualPatientProvider               1.636980\n",
       "OP_Perc_MultHosp                  0.674412\n",
       "IP_Mean_InsReimbursementRatio     0.379315\n",
       "OP_Count_UniqueState              0.228130\n",
       "IP_Perc_HeartFailure_Chronic      0.143150\n",
       "Perc_MultHospAttPhys              0.057042\n",
       "IP_Perc_Depression_Chronic        0.005872"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients = pd.DataFrame(bestLogReg.coef_.T, index=X.columns\n",
    "                           ).rename(columns = {0:'Coefficient'}\n",
    "                           ).abs().sort_values(by='Coefficient',\n",
    "                                               ascending=False)\n",
    "coefficients[coefficients.Coefficient > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.4144736842105263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sitat\\anaconda3\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.22.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\sitat\\anaconda3\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.22.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# max_features default is 'auto' (sqrt(n_features))\n",
    "randForestModel = \\\n",
    "    RandomForestClassifier(class_weight='balanced', random_state=0)\n",
    "\n",
    "randForestModel.fit(X_train, y_train)\n",
    "\n",
    "# dump(randForestModel, './data/randForestModel.pkl')\n",
    "\n",
    "randForestModel = load('./data/randForestModel.pkl')\n",
    "print(recall_score(y_train, randForestModel.predict(X_train)))\n",
    "print(recall_score(y_test, randForestModel.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sitat\\anaconda3\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.22.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\sitat\\anaconda3\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.22.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# params = {'n_estimators': [100,1000,5000],\n",
    "#           'max_depth': np.linspace(5,50,5),\n",
    "#           'max_features' : np.arange(1,11)}\n",
    "\n",
    "# randForestGS = ms.GridSearchCV(randForestModel, param_grid=params,\n",
    "#                                     scoring='recall', cv=skfold,\n",
    "#                                     n_jobs=-1, verbose=1)\n",
    "\n",
    "# randForest = randForestGS.fit(X_train, y_train)\n",
    "\n",
    "# bestRandForest = randForest.best_estimator_\n",
    "# print(bestRandForest)\n",
    "\n",
    "best_randForest = load('./data/best_randForest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9293785310734464\n",
      "0.9276315789473685\n"
     ]
    }
   ],
   "source": [
    "# print(best_randForest)\n",
    "# print(best_randForest.score(X_train, y_train))\n",
    "# print(best_randForest.score(X_test, y_test))\n",
    "\n",
    "print(recall_score(y_train, best_randForest.predict(X_train)))\n",
    "print(recall_score(y_test, best_randForest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = imblearn.over_sampling.SMOTE(random_state=0)\n",
    "X_train_SMOTE, y_train_SMOTE = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9796096708418293\n",
      "0.743421052631579\n"
     ]
    }
   ],
   "source": [
    "gradBoostModel = GradientBoostingClassifier(max_features='auto', random_state=0)\n",
    "gradBoostModel.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "\n",
    "print(recall_score(y_train_SMOTE, gradBoostModel.predict(X_train_SMOTE)))\n",
    "print(recall_score(y_test, gradBoostModel.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/gradBoostModel.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump(gradBoostModel, './data/gradBoostModel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 243 candidates, totalling 2430 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 25.4min\n",
      "C:\\Users\\sitat\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 176.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 219.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 378.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2430 out of 2430 | elapsed: 549.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(max_depth=9, max_features=1, min_samples_leaf=3,\n",
      "                           n_estimators=1000, random_state=0)\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': [100, 1000, 5000],\n",
    "          'learning_rate':[0.05, 0.1, 0.5],\n",
    "          'min_samples_leaf': [1, 3, 5],\n",
    "          'max_depth': np.arange(1, 20, 8),\n",
    "          'max_features' : np.arange(1, 20, 8)}\n",
    "\n",
    "gradBoostGS = ms.GridSearchCV(gradBoostModel, param_grid=params,\n",
    "                                    scoring='recall', cv=skfold,\n",
    "                                    n_jobs=-1, verbose=1)\n",
    "\n",
    "gradBoost = gradBoostGS.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "\n",
    "bestGradBoost = gradBoost.best_estimator_\n",
    "dump(bestGradBoost, './data/bestGradBoost.pkl')\n",
    "\n",
    "# bestGradBoost = load('./data/bestGradBoost.pkl')\n",
    "print(bestGradBoost)\n",
    "print(recall_score(y_train_SMOTE, bestGradBoost.predict(X_train_SMOTE)))\n",
    "print(recall_score(y_test, bestGradBoost.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importances(model):\n",
    "    df = pd.DataFrame({'feature': np.array(X.columns),\n",
    "                       'importance': model.feature_importances_}\n",
    "                     ).sort_values('importance')\n",
    "    return px.bar(df, 'importance', 'feature', height=1000)\n",
    "# feature_importances(gradBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_reduced = pd.DataFrame(X_train, columns=X.columns)\n",
    "# X_train_reduced = X_train_reduced.iloc[:,:len(gradBoost.feature_importances_\n",
    "#                           [gradBoost.feature_importances_ > 0.005])];\n",
    "\n",
    "# X_test_reduced = pd.DataFrame(X_test, columns=X.columns)\n",
    "# X_test_reduced = X_test_reduced.iloc[:,:len(gradBoost.feature_importances_\n",
    "#                           [gradBoost.feature_importances_ > 0.005])];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradBoost_reduced = gradBoost.fit(X_train_reduced, y_train)\n",
    "\n",
    "# print(np.mean(ms.cross_val_score(gradBoost_reduced, X_train_reduced, y_train, cv=10)))\n",
    "# print(gradBoost_reduced.score(X_test_reduced, y_test))\n",
    "\n",
    "# FI at all FI: 0.9406473665086488/0.9426987060998152\n",
    "# FI at 0.001: 0.9429039808688451/0.9408502772643254\n",
    "# FI at 0.005: 0.9279121352701092/0.9297597042513863"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
